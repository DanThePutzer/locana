{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "93423d6b-7ffc-4a4f-9415-6feca832ce59",
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9111ec48-4b94-4430-8115-45e7e5a2afa1"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "import pickle\n",
    "\n",
    "# Scikit-Learn Tools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow Tools\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D, Flatten\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Experimenting with Dask\n",
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if Tensorflow is running on GPU\n",
    "print(f\"Built With CUDA: { tf.test.is_built_with_cuda() }\")\n",
    "print(f\"Available GPU: { tf.config.list_physical_devices('GPU') }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model IO Variables\n",
    "\n",
    "\n",
    "\n",
    "#### Retrain Model?\n",
    "* If the model should be trained from scratch, set retrainModel to **True**  \n",
    "* If you want to import saved weights from a pretrained model set retrainModel to **False**\n",
    "\n",
    "***\n",
    "\n",
    "#### Override Weights?\n",
    "* If newly trained weights should replace the old saved weights set overrideOldWeights to **True**  \n",
    "* If you wish to keep the old weights saved as they are set overrideOldWeights to **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting model IO variables\n",
    "retrainModel = True\n",
    "pretrainedWeightsPath = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "18ad88ee-f544-4d1d-91aa-c376965d320d",
    "tags": []
   },
   "source": [
    "### Loading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "9b130c0e-de7a-4a41-8600-406f53e87bd7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up empty lists for data\n",
    "imageLabels, imageData = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5cc5d96e-5f83-4d3b-820c-7cacf57eebc8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to fetch images and turn them into numpy arrays\n",
    "def loadImageData(mainDirectory):\n",
    "    # Iterating over categories\n",
    "    for category in os.listdir(mainDirectory):\n",
    "        # Iterating over images in category\n",
    "        for imageName in tqdm(os.listdir(os.path.join(mainDirectory + category)), desc = f'Loading {category}'):\n",
    "            # Loading image with pillow\n",
    "            image = Image.open(os.path.join(mainDirectory, category, imageName))\n",
    "            # Converting to numpy array\n",
    "            data = np.asarray(image)\n",
    "\n",
    "            # Appending label and data to training lists\n",
    "            imageLabels.append(category)\n",
    "            imageData.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "af387805-15a8-409b-868b-03f4bd7f7d3b",
    "output_cleared": false
   },
   "outputs": [],
   "source": [
    "# Loading images\n",
    "loadImageData('./Data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffling data and labels in unison\n",
    "shuffleFrame = list(zip(imageData, imageLabels))\n",
    "random.shuffle(shuffleFrame)\n",
    "\n",
    "imageData, imageLabels = zip(*shuffleFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "44ea8685-9ca9-4113-b9a6-09aac3ab1e7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting image data to numpy array\n",
    "imageData = np.array(imageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "22b3c4fb-82b1-4abd-82f5-3b64de5995db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-Hot encoding label list\n",
    "imageLabels = np.array(imageLabels).reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "imageLabels = encoder.fit_transform(imageLabels).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping data to fit model and augmentation generator\n",
    "# Shape info: (Number of images, Height of image, Width of image, Channels)\n",
    "# 'Number of images' is -1 so this dimension will be determined by numpy automatically based on the other fixed parameters\n",
    "# 'Channels' is 1 because we use greyscale images -> only one color channel\n",
    "imageData = imageData.reshape(-1, 240, 640, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing shape of training data\n",
    "print(f\"Data Shape: {imageData.shape}\")\n",
    "print(f\"Labels Shape: {imageLabels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into train and test data\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(imageData, imageLabels, test_size = 0.25, random_state = 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting turning train data into Dask array\n",
    "chunkedTrainData = da.from_array(trainData, chunks = (1250, 240, 640, 1)) # 1250\n",
    "chunkedTrainLabels = da.from_array(trainLabels, chunks = (1250, 10))\n",
    "\n",
    "# Splitting turning test data into Dask array\n",
    "chunkedTestData = da.from_array(testData, chunks = (420, 240, 640, 1)) # 420\n",
    "chunkedTestLabels = da.from_array(testLabels, chunks = (420, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickling Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving processed data to pickle\n",
    "dataPickle = open('Pickles/imageData.pkl', 'wb')\n",
    "pickle.dump(imageData, dataPickle)\n",
    "dataPickle.close()\n",
    "\n",
    "# Saving processed labels to pickle\n",
    "labelPickle = open('Pickles/imageLabel.pkl', 'wb')\n",
    "pickle.dump(imageLabels, labelPickle)\n",
    "labelPickle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation With ImageDataGenerators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining training data generator\n",
    "trainDataGen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")\n",
    "\n",
    "# Defining test data generator\n",
    "testDataGen = ImageDataGenerator(\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "dbcc1f2e-7671-4b72-a8c2-2d5bba2b578d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating model called locana (Sanskrit for 'Vision')\n",
    "locana = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting dummy input to avoid OOM error\n",
    "dummy = tf.zeros((1, 240, 640, 1))\n",
    "locana._set_inputs(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "5e7e2fcd-0122-458b-b447-c664fcf5e515",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up layers\n",
    "\n",
    "# Convolutional layer 1\n",
    "locana.add(Conv2D(32, kernel_size = 5, activation = 'relu', input_shape = (240, 640, 1)))\n",
    "locana.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Convolutional layer 2\n",
    "locana.add(Conv2D(64, kernel_size = 3, activation = 'relu'))\n",
    "locana.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Convolutional layer 3\n",
    "locana.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\n",
    "locana.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flattening and first dense layer\n",
    "locana.add(Flatten())\n",
    "locana.add(Dense(128, activation = 'relu'))\n",
    "\n",
    "# Output layer\n",
    "locana.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "cbbb927b-9b58-47a0-9864-65d3cfd51a54",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "locana.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting training parameters\n",
    "batchSize = 8\n",
    "epochsPerChunk = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function managing individual train iteration\n",
    "def trainingIteration(trainChunk, trainChunkLabels, testChunk, testChunkLabels):\n",
    "    # Fitting training data generator to train data\n",
    "    trainDataGen.fit(trainChunk)\n",
    "    \n",
    "    # Fitting test data generator to test data\n",
    "    testDataGen.fit(testChunk)\n",
    "    \n",
    "    # Training model on given chunk\n",
    "    locana.fit(\n",
    "        trainDataGen.flow(trainChunk, trainChunkLabels, batch_size = batchSize),\n",
    "        validation_data = testDataGen.flow(testChunk, testChunkLabels, batch_size = batchSize),\n",
    "        steps_per_epoch = len(trainChunk) / batchSize,\n",
    "        epochs = epochsPerChunk\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    # Iterating over chunks in train data dask array\n",
    "    for index, trainChunk in tqdm(enumerate(chunkedTrainData.blocks), total = 12, desc = \"Training On Chunks\"):\n",
    "        # Retrieving appropriate train label chunk from Dask array\n",
    "        trainLabels = chunkedTrainLabels.blocks[index]\n",
    "        # Retrieving appropriate test data chunk from Dask array\n",
    "        testChunk = chunkedTestData.blocks[index]\n",
    "        # Retrieving appropriate test label chunk from Dask array\n",
    "        testLabels = chunkedTestLabels.blocks[index]\n",
    "\n",
    "        print(f'- - - Chunk {index + 1} - - -')\n",
    "        # Executing train iteration with current chunk data\n",
    "        trainingIteration(trainChunk, trainLabels, testChunk, testLabels)\n",
    "        # Garbage collection to keep memory clean\n",
    "        print(f'Collected Garbage: {gc.collect()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "2d2c2f5c-1923-4f2e-a31b-d0733ca4752d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "if retrainModel:\n",
    "    # Training model on train data\n",
    "    trainModel()\n",
    "    # Overriding old saved weights if so chosen\n",
    "    if len(pretrainedWeightsPath) == 0: locana.save_weights('pretrainedLocana.h5')\n",
    "else:\n",
    "    # Load pretrained GPU weights\n",
    "    locana.load_weights(pretrainedWeightsPath)"
   ]
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [
   {
    "cellId": "2d2c2f5c-1923-4f2e-a31b-d0733ca4752d",
    "msgId": "91074861-7a76-4f89-aae1-6cd5e461edd6",
    "sessionId": "3585cf04-e23a-46b1-aa16-4358d33d4497"
   }
  ],
  "deepnote_notebook_id": "1b5dc682-6efd-4fd5-8d17-02d88e9833d0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
