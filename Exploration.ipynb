{"cells":[{"cell_type":"markdown","source":"### Initialization","metadata":{"tags":[],"cell_id":"93423d6b-7ffc-4a4f-9415-6feca832ce59"}},{"cell_type":"code","metadata":{"cell_id":"9111ec48-4b94-4430-8115-45e7e5a2afa1"},"source":"# Importing libraries\r\nimport tensorflow as tf\r\nimport pandas as pd\r\nimport numpy as np\r\nfrom tqdm.notebook import tqdm\r\nimport gc\r\nfrom PIL import Image\r\nimport os\r\n\r\n# Scikit-Learn Tools\r\nfrom sklearn.preprocessing import OneHotEncoder\r\nfrom sklearn.model_selection import train_test_split\r\n\r\n# Tensorflow Tools\r\nfrom tensorflow.keras.models import Sequential\r\nfrom tensorflow.keras.layers import Dense, Conv2D, Flatten","execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Loading Image Data","metadata":{"tags":[],"cell_id":"18ad88ee-f544-4d1d-91aa-c376965d320d"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"9b130c0e-de7a-4a41-8600-406f53e87bd7"},"source":"# Setting up empty lists for data\r\nimageLabels, imageData = [], []","execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"5cc5d96e-5f83-4d3b-820c-7cacf57eebc8"},"source":"# Function to fetch images and turn them into numpy arrays\r\ndef loadImageData(mainDirectory):\r\n    # Iterating over categories\r\n    for category in os.listdir(mainDirectory):\r\n        # Iterating over images in category\r\n        for imageName in tqdm(os.listdir(os.path.join(mainDirectory + category)), desc = 'Loading Images'):\r\n            # Loading image with pillow\r\n            image = Image.open(os.path.join(mainDirectory, category, imageName))\r\n            # Converting to numpy array\r\n            data = np.asarray(image)\r\n\r\n            # Appending label and data to training lists\r\n            imageLabels.append(category)\r\n            imageData.append(data)\r\n","execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"cell_id":"af387805-15a8-409b-868b-03f4bd7f7d3b","output_cleared":false},"source":"# Loading images\r\nloadImageData('./Data/')","execution_count":4,"outputs":[{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a4c7aa8567ed40cc860444d0a9ed6ae7"}},"metadata":{},"output_type":"display_data"},{"name":"stdout","text":"\n","output_type":"stream"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a0bedc8713749249e4ef7ef642e777c"}},"metadata":{},"output_type":"display_data","text":"\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d49d891b061d4cd191e4194072aacb09"}},"metadata":{},"output_type":"display_data","text":"\n\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afdc51ce6d814696835a6fcfb928a99c"}},"metadata":{},"output_type":"display_data","text":"\n\n\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f6888ef20ee4c2ba1422a7777c0153c"}},"metadata":{},"output_type":"display_data","text":"\n\n\n\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a31a336e8fca4dc8ab6969d3888a8807"}},"metadata":{},"output_type":"display_data","text":"\n\n\n\n\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee976664a754a55abaadd02c4934c31"}},"metadata":{},"output_type":"display_data","text":"\n\n\n\n\n\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"955d1868437a46b48f1c9f1e0f6f7df2"}},"metadata":{},"output_type":"display_data","text":"\n\n\n\n\n\n\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6cfd4cac56774e0b8f7be1c794069c1b"}},"metadata":{},"output_type":"display_data","text":"\n\n\n\n\n\n\n\n\n"},{"data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b898656a757b4ca7ac09c3ff19646c49"}},"metadata":{},"output_type":"display_data","text":"\n\n\n\n\n\n\n\n\n\n"}]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"44ea8685-9ca9-4113-b9a6-09aac3ab1e7f"},"source":"# Converting image data to numpy array\r\nimageData = np.array(imageData)","execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"tags":[],"cell_id":"22b3c4fb-82b1-4abd-82f5-3b64de5995db"},"source":"# One-Hot encoding label list\r\nimageLabels = np.array(imageLabels).reshape(-1, 1)\r\n\r\nencoder = OneHotEncoder()\r\nimageLabels = encoder.fit_transform(imageLabels).toarray()","execution_count":7,"outputs":[]},{"cell_type":"code","source":"# Reshaping data to fit model\r\n# Shape info: (Number of images, Height of image, Width of image, Channels)\r\n# 'Number of images' is -1 so this dimension will be determined by numpy automatically based on the other fixed parameters\r\n# 'Channels' is 1 because we use greyscale images -> only one color channel\r\nimageData = imageData.reshape(-1, 240, 640, 1)","metadata":{"tags":[],"cell_id":"6f3aa765-0224-458d-81df-f1e79f0e3b8d"},"outputs":[],"execution_count":8},{"cell_type":"code","metadata":{"tags":[],"cell_id":"1a3bbb2b-2378-4ef5-880a-172162e55a79"},"source":"# Assessing shape of training data\r\nprint(f\"Data Shape: {imageData.shape}\")\r\nprint(f\"Labels Shape: {imageLabels.shape}\")","execution_count":9,"outputs":[{"name":"stdout","text":"Data Shape: (2000, 240, 640, 1)\nLabels Shape: (2000, 10)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Splitting into train and test sets\r\ntrainData, testData, trainLabels, testLabels = train_test_split(imageData, imageLabels, test_size = 0.25, random_state = 111)","metadata":{"tags":[],"cell_id":"2d8d3090-20a9-472a-9465-28222ce01043"},"outputs":[],"execution_count":10},{"cell_type":"markdown","source":"### Creating first model","metadata":{"tags":[],"cell_id":"70d78311-4833-4f88-8f4d-f4cb43150a7a"}},{"cell_type":"code","metadata":{"tags":[],"cell_id":"dbcc1f2e-7671-4b72-a8c2-2d5bba2b578d"},"source":"# Creating model called locana (Sanskrit for 'Vision')\r\nlocana = Sequential()","execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Settin up layers\r\nlocana.add(Conv2D(64, kernel_size = 3, activation = 'relu', input_shape = (240, 640, 1)))\r\nlocana.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\r\nlocana.add(Flatten())\r\nlocana.add(Dense(10, activation = 'softmax'))","metadata":{"tags":[],"cell_id":"5e7e2fcd-0122-458b-b447-c664fcf5e515"},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# Compiling model\r\nlocana.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])","metadata":{"tags":[],"cell_id":"cbbb927b-9b58-47a0-9864-65d3cfd51a54"},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Training model on train data\r\nlocana.fit(trainData, trainLabels, validation_data = (testData, testLabels), epochs = 3)","metadata":{"tags":[],"cell_id":"2d2c2f5c-1923-4f2e-a31b-d0733ca4752d"},"outputs":[{"name":"stdout","text":"Epoch 1/3\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{"tags":[],"cell_id":"eccbd3b8-327e-468c-9d75-3970b6934197"},"outputs":[],"execution_count":null}],"nbformat":4,"nbformat_minor":2,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"},"deepnote_notebook_id":"1b5dc682-6efd-4fd5-8d17-02d88e9833d0","deepnote_execution_queue":[{"cellId":"2d2c2f5c-1923-4f2e-a31b-d0733ca4752d","sessionId":"3585cf04-e23a-46b1-aa16-4358d33d4497","msgId":"91074861-7a76-4f89-aae1-6cd5e461edd6"}]}}