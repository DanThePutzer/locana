{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "93423d6b-7ffc-4a4f-9415-6feca832ce59",
    "tags": []
   },
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "9111ec48-4b94-4430-8115-45e7e5a2afa1"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import gc\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Scikit-Learn Tools\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Tensorflow Tools\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built With CUDA: True\n",
      "GPU Available: True\n",
      "GPU Device Name: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# Checking if Tensorflow is running on GPU\n",
    "print(f\"Built With CUDA: { tf.test.is_built_with_cuda() }\")\n",
    "print(f\"GPU Available: { tf.test.is_gpu_available() }\")\n",
    "print(f\"GPU Device Name: { tf.test.gpu_device_name() }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Model IO Variables\n",
    "\n",
    "\n",
    "\n",
    "#### Retrain Model?\n",
    "* If the model should be trained from scratch, set retrainModel to **True**  \n",
    "* If you want to import saved weights from a pretrained model set retrainModel to **False**\n",
    "\n",
    "***\n",
    "\n",
    "#### Override Weights?\n",
    "* If newly trained weights should replace the old saved weights set overrideOldWeights to **True**  \n",
    "* If you wish to keep the old weights saved as they are set overrideOldWeights to **False**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting model IO variables\n",
    "retrainModel = True\n",
    "overrideOldWeights = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "18ad88ee-f544-4d1d-91aa-c376965d320d",
    "tags": []
   },
   "source": [
    "### Loading Image Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell_id": "9b130c0e-de7a-4a41-8600-406f53e87bd7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setting up empty lists for data\n",
    "imageLabels, imageData = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell_id": "5cc5d96e-5f83-4d3b-820c-7cacf57eebc8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to fetch images and turn them into numpy arrays\n",
    "def loadImageData(mainDirectory):\n",
    "    # Iterating over categories\n",
    "    for category in os.listdir(mainDirectory):\n",
    "        # Iterating over images in category\n",
    "        for imageName in tqdm(os.listdir(os.path.join(mainDirectory + category)), desc = 'Loading Images'):\n",
    "            # Loading image with pillow\n",
    "            image = Image.open(os.path.join(mainDirectory, category, imageName))\n",
    "            # Converting to numpy array\n",
    "            data = np.asarray(image)\n",
    "\n",
    "            # Appending label and data to training lists\n",
    "            imageLabels.append(category)\n",
    "            imageData.append(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "cell_id": "af387805-15a8-409b-868b-03f4bd7f7d3b",
    "output_cleared": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7173686cfd7d4914be3d2ef98b9496d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "560bd09bb4844559af7772f41b95db69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6010f1fa5b3c43da8a57104a1ff29084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7af41737e594e76835c2da4c4297395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfd8e1579cba44b7af32bd51b5f42cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c72a0519d746739aff6f16a4985cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12429321441348f7a23c58d8d822663a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5a1bfec9fb48e5ad14ded36fa313d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "930c08d05c294506bb15b01a4d5b07f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd84d81b5a54d0dbcb01a1fc92ad31e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading Images', max=200.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Loading images\n",
    "loadImageData('./Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell_id": "44ea8685-9ca9-4113-b9a6-09aac3ab1e7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converting image data to numpy array\n",
    "imageData = np.array(imageData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell_id": "22b3c4fb-82b1-4abd-82f5-3b64de5995db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# One-Hot encoding label list\n",
    "imageLabels = np.array(imageLabels).reshape(-1, 1)\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "imageLabels = encoder.fit_transform(imageLabels).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "cell_id": "6f3aa765-0224-458d-81df-f1e79f0e3b8d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshaping data to fit model\n",
    "# Shape info: (Number of images, Height of image, Width of image, Channels)\n",
    "# 'Number of images' is -1 so this dimension will be determined by numpy automatically based on the other fixed parameters\n",
    "# 'Channels' is 1 because we use greyscale images -> only one color channel\n",
    "imageData = imageData.reshape(-1, 240, 640, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell_id": "1a3bbb2b-2378-4ef5-880a-172162e55a79",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (2000, 240, 640, 1)\n",
      "Labels Shape: (2000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Assessing shape of training data\n",
    "print(f\"Data Shape: {imageData.shape}\")\n",
    "print(f\"Labels Shape: {imageLabels.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell_id": "2d8d3090-20a9-472a-9465-28222ce01043",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting into train and test sets\n",
    "trainData, testData, trainLabels, testLabels = train_test_split(imageData, imageLabels, test_size = 0.25, random_state = 111)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "70d78311-4833-4f88-8f4d-f4cb43150a7a",
    "tags": []
   },
   "source": [
    "### Creating first model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "cell_id": "dbcc1f2e-7671-4b72-a8c2-2d5bba2b578d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating model called locana (Sanskrit for 'Vision')\n",
    "locana = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting dummy input to avoid OOM error\n",
    "dummy = tf.zeros((1, 240, 640, 1))\n",
    "locana._set_inputs(dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "cell_id": "5e7e2fcd-0122-458b-b447-c664fcf5e515",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Settin up layers\n",
    "locana.add(Conv2D(64, kernel_size = 3, activation = 'relu', input_shape = (240, 640, 1)))\n",
    "locana.add(Conv2D(32, kernel_size = 3, activation = 'relu'))\n",
    "locana.add(Flatten())\n",
    "locana.add(Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "cell_id": "cbbb927b-9b58-47a0-9864-65d3cfd51a54",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compiling model\n",
    "locana.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "cell_id": "2d2c2f5c-1923-4f2e-a31b-d0733ca4752d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1500 samples, validate on 500 samples\n",
      "Epoch 1/3\n",
      "1500/1500 [==============================] - 53s 36ms/sample - loss: 135.5239 - accuracy: 0.8933 - val_loss: 0.0744 - val_accuracy: 0.9920\n",
      "Epoch 2/3\n",
      "1500/1500 [==============================] - 50s 33ms/sample - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.0624 - val_accuracy: 0.9960\n",
      "Epoch 3/3\n",
      "1500/1500 [==============================] - 52s 35ms/sample - loss: 2.1664e-05 - accuracy: 1.0000 - val_loss: 0.0610 - val_accuracy: 0.9960\n"
     ]
    }
   ],
   "source": [
    "if retrainModel:\n",
    "    # Training model on train data\n",
    "    locana.fit(trainData, trainLabels, batch_size = 8, validation_data = (testData, testLabels), epochs = 3)\n",
    "    # Overriding old saved weights if so chosen\n",
    "    if overrideOldWeights: locana.save_weights('pretrainedLocanaWeights.h5')\n",
    "else:\n",
    "    # Load pretrained GPU weights\n",
    "    locana.load_weights('pretrainedLocanaWeights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "eccbd3b8-327e-468c-9d75-3970b6934197",
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "deepnote_execution_queue": [
   {
    "cellId": "2d2c2f5c-1923-4f2e-a31b-d0733ca4752d",
    "msgId": "91074861-7a76-4f89-aae1-6cd5e461edd6",
    "sessionId": "3585cf04-e23a-46b1-aa16-4358d33d4497"
   }
  ],
  "deepnote_notebook_id": "1b5dc682-6efd-4fd5-8d17-02d88e9833d0",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
